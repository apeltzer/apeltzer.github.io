<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Personal Homepage of Alex Peltzer</title>
    <link>https://apeltzer.github.io/</link>
      <atom:link href="https://apeltzer.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Personal Homepage of Alex Peltzer</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>2021</copyright><lastBuildDate>Fri, 23 Oct 2020 00:00:00 +0200</lastBuildDate>
    <image>
      <url>https://apeltzer.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Personal Homepage of Alex Peltzer</title>
      <link>https://apeltzer.github.io/</link>
    </image>
    
    <item>
      <title>Interpretations of microbial community studies are biased by the selected 16S rRNA gene amplicon sequencing pipeline.</title>
      <link>https://apeltzer.github.io/publication/17-ampliseq/</link>
      <pubDate>Fri, 23 Oct 2020 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/17-ampliseq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DamageProfiler: Fast damage pattern calculation for ancient DNA</title>
      <link>https://apeltzer.github.io/publication/18-damageprofiler/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/18-damageprofiler/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scalable, reproducible bioinformatics workflows using Nextflow &amp; nf-core</title>
      <link>https://apeltzer.github.io/talk/scalable-reproducible-bioinformatics-workflows-using-nextflow-nf-core/</link>
      <pubDate>Wed, 02 Sep 2020 15:30:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/scalable-reproducible-bioinformatics-workflows-using-nextflow-nf-core/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reproducible, portable, and effcient ancient genome reconstruction with nf-core/eager</title>
      <link>https://apeltzer.github.io/publication/16-eager/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/16-eager/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scalable, reproducible bioinformatics workflows using Nextflow &amp; nf-core</title>
      <link>https://apeltzer.github.io/talk/scalable-reproducible-bioinformatics-workflows-using-nextflow-nf-core/</link>
      <pubDate>Fri, 03 Apr 2020 09:30:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/scalable-reproducible-bioinformatics-workflows-using-nextflow-nf-core/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ten simple rules for providing effective bioinformatics research support</title>
      <link>https://apeltzer.github.io/publication/15-tenrules/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/publication/15-tenrules/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The nf-core framework for community-curated bioinformatics pipelines</title>
      <link>https://apeltzer.github.io/publication/14-nfcore/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/publication/14-nfcore/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scalable, reproducible bioinformatics workflows using Nextflow &amp; nf-core</title>
      <link>https://apeltzer.github.io/talk/scalable-reproducible-bioinformatics-workflows-using-nextflow-nf-core/</link>
      <pubDate>Tue, 14 Jan 2020 09:30:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/talk/scalable-reproducible-bioinformatics-workflows-using-nextflow-nf-core/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interpretations of microbial community studies are biased by the selected 16S rRNA gene amplicon sequencing pipeline.</title>
      <link>https://apeltzer.github.io/publication/13-ampliseq/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/publication/13-ampliseq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Potent Antitumor Activity of Liposomal Irinotecan in an Organoid- and CRISPR-Cas9-Based Murine Model of Gallbladder Cancer</title>
      <link>https://apeltzer.github.io/publication/12-antitumor/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/publication/12-antitumor/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MHCquant: Automated and reproducible data analysis for immunopeptidomics</title>
      <link>https://apeltzer.github.io/publication/11-mhcquant/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/11-mhcquant/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Migrating legacy workflows to Nextflow</title>
      <link>https://apeltzer.github.io/talk/migrating-legacy-workflows-to-nextflow/</link>
      <pubDate>Thu, 19 Sep 2019 09:45:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/migrating-legacy-workflows-to-nextflow/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BigData analytics with Nextflow and nf-core</title>
      <link>https://apeltzer.github.io/talk/bigdata-analytics-with-nextflow-and-nf-core/</link>
      <pubDate>Tue, 03 Sep 2019 11:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/bigdata-analytics-with-nextflow-and-nf-core/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Challenges of big data integration in the life sciences</title>
      <link>https://apeltzer.github.io/publication/10-bigdata/</link>
      <pubDate>Wed, 28 Aug 2019 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/10-bigdata/</guid>
      <description></description>
    </item>
    
    <item>
      <title>nf-core: Community built bioinformatics pipelines</title>
      <link>https://apeltzer.github.io/talk/nf-core-community-built-bioinformatics-pipelines/</link>
      <pubDate>Fri, 26 Jul 2019 09:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/nf-core-community-built-bioinformatics-pipelines/</guid>
      <description></description>
    </item>
    
    <item>
      <title>nf-core: Community built bioinformatics pipelines</title>
      <link>https://apeltzer.github.io/talk/nf-core-community-built-bioinformatics-pipelines/</link>
      <pubDate>Thu, 25 Jul 2019 14:20:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/nf-core-community-built-bioinformatics-pipelines/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BigData Analytics with Nextflow &amp; nf-core</title>
      <link>https://apeltzer.github.io/talk/bigdata-analytics-with-nextflow-nf-core/</link>
      <pubDate>Sat, 06 Jul 2019 11:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/bigdata-analytics-with-nextflow-nf-core/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Affordable WGS for personal usage (part 1)</title>
      <link>https://apeltzer.github.io/post/02-dante-wgs/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/post/02-dante-wgs/</guid>
      <description>&lt;h2 id=&#34;how-and-why-i-did-it&#34;&gt;How and why I did it&lt;/h2&gt;
&lt;p&gt;I was already interested in sequencing my own genome during my time as a Ph.D. student, when the first 23andme &amp;amp; other genotyping services were available publicly. After all, back then this wasn&amp;rsquo;t as exciting as I thought due to quite restricted resolution. Having access to the full genome-wide data was something I didn&amp;rsquo;t think about for a while.&lt;/p&gt;
&lt;p&gt;During last years Black Friday event, I decided to take the opportunity to pay for my own genome to be sequenced using &lt;a href=&#34;http://dantelabs.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DanteLabs&lt;/a&gt; WGZ &amp;ldquo;Black Friday Offer&amp;rdquo;. After the payment, I figured out that in order to get the final &lt;a href=&#34;https://en.wikipedia.org/wiki/SAM_%28file_format%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BAM&lt;/a&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/FASTQ_format&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FastQ&lt;/a&gt; file formats that you need to additionally pay US$ 50 to get an external harddisk with your &amp;ldquo;real&amp;rdquo; RAW data.&lt;/p&gt;
&lt;p&gt;Without that, you will receive VCF file(s) for SNPs, CNVs, SVs, INDELs and two PDFs with two individual reports for medications and health-related insights. The Bioinformatician in me was however more interested in doing everything from scratch which I&amp;rsquo;m going to explicitly elucidate here a bit upon. The data looks very similar to standard Illumina data I already have some experience with, so standard WGS/WES pipeline analysis was the way to go for looking into it in more detail. Feel free to ask me on &lt;a href=&#34;https://twitter.com/alex_peltzer/status/1122589887054721026&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twitter&lt;/a&gt; for more details - I might update this or do several follow ups on this posting to keep people with interest in the loop.&lt;/p&gt;
&lt;h2 id=&#34;delivery&#34;&gt;Delivery&lt;/h2&gt;
&lt;p&gt;Upon registering and paying upfront, I got my swab kit approximately 2 weeks after payment. Immediately after sending it in, it took another about 4 weeks to get confirmation that DNA extraction went successful and I got access to the data at the website to at least download the two pdf report and my VCF files.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2019-04-28_wgz/01_report.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Upon receiving this, it took another 6 weeks until I got my RAW data in April 2019. The harddisk has 500GB and contained raw data with compressed FastQ (split across multiple lanes), some QC files, BAM and Index for that final BAM and the called Variants found on the website as VCF files.&lt;/p&gt;
&lt;h2 id=&#34;first-analysis-steps&#34;&gt;First Analysis Steps&lt;/h2&gt;
&lt;p&gt;I decided to utilize a pipeline for modern WGS sequencing to analyze my data in a single run. My choice for this job was the &lt;a href=&#34;https://github.com/SciLifeLab/Sarek&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sarek&lt;/a&gt; pipeline which can do all of the required steps for such an analysis in an easy manner, including QC, mapping, variant calling, annotation and reporting.&lt;/p&gt;
&lt;h3 id=&#34;step-1-create-a-tsv-file&#34;&gt;Step 1: Create a TSV file&lt;/h3&gt;
&lt;p&gt;First step was to create a TSV file with my data in it. I anonymized some parts here for privacy reasons but it should be quite straightforward &lt;a href=&#34;https://github.com/SciLifeLab/Sarek/blob/master/docs/INPUT.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;what the columns mean&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Alex    XY      0       Alex_Normal     15180   RAW/foo15180_L01_543_1.fastq.gz RAW/foo15180_L01_543_2.fastq.gz
Alex    XY      0       Alex_Normal     525     RAW/foo_L01_525_1.fastq.gz  RAW/foo_L01_525_2.fastq.gz
Alex    XY      0       Alex_Normal     526     RAW/foo_L01_526_1.fastq.gz  RAW/foo_L01_526_2.fastq.gz
Alex    XY      0       Alex_Normal     527     RAW/foo_L01_527_1.fastq.gz  RAW/foo_L01_527_2.fastq.gz
Alex    XY      0       Alex_Normal     528     RAW/foo_L01_528_1.fastq.gz  RAW/foo_L01_528_2.fastq.gz
Alex    XY      0       Alex_Normal     529     RAW/foo_L01_529_1.fastq.gz  RAW/foo_L01_529_2.fastq.gz
Alex    XY      0       Alex_Normal     530     RAW/foo_L01_530_1.fastq.gz  RAW/foo_L01_530_2.fastq.gz
Alex    XY      0       Alex_Normal     531     RAW/foo_L01_531_1.fastq.gz  RAW/foo_L01_531_2.fastq.gz
Alex    XY      0       Alex_Normal     532     RAW/foo_L01_532_1.fastq.gz  RAW/foo_L01_532_2.fastq.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;step-2-run-mapping--qc&#34;&gt;Step 2: Run Mapping / QC&lt;/h3&gt;
&lt;p&gt;Second, I started the mapping and initial QC for the data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nextflow run SciLifeLab/Sarek/main.nf -r dev -profile standard,docker --genome &#39;GRCh37&#39; --sample sarek.tsv -resume
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;step-3-run-variantcalling&#34;&gt;Step 3: Run VariantCalling&lt;/h3&gt;
&lt;p&gt;As I was uncertain which VariantCallers would give me best results, I just selected all of the variant callers available in Sarek for germline data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nextflow run SciLifeLab/Sarek/germlineVC.nf -profile standard,docker -r dev --genome &#39;GRCh37&#39; --sample Preprocessing/Recalibrated/recalibrated.tsv --tools &#39;HaplotypeCaller,strelka,manta&#39; -resume
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;step-4-annotate-the-results--create-a-report&#34;&gt;Step 4: Annotate the results &amp;amp; create a report&lt;/h3&gt;
&lt;p&gt;Having only the raw variants isn&amp;rsquo;t really useful without annotation:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nextflow run SciLifeLab/Sarek/annotate.nf -profile standard,docker -r dev --genome &#39;GRCh37&#39; --annotateTools &#39;HaplotypeCaller,strelka,manta&#39; --tools &#39;snpEff&#39;
nextflow run SciLifeLab/Sarek/runMultiQC.nf -r dev -profile standard,docker
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;some-basic-statistics-and-information&#34;&gt;Some basic statistics and information&lt;/h2&gt;
&lt;h3 id=&#34;general-qc&#34;&gt;General QC&lt;/h3&gt;
&lt;p&gt;The data looks quite good in terms of basic metrics on the raw data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2019-04-28_wgz/fastqc_per_base_sequence_quality_plot.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;As I mapped against the GRCh37 genome reference, all these reported values are against that. In total, 936 Million reads were properly mapped, with a 41%GC content. A total coverage of 31X was achieved, with 90.6% of the genome covered at least with 10X, and 56.7% of the genome covered with at least 30X as reported by the Sarek reports.&lt;/p&gt;
&lt;h3 id=&#34;hlatyping&#34;&gt;HLATyping&lt;/h3&gt;
&lt;p&gt;I also extracted all of the reads on Chromosome 6:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;samtools view -bh -o chr6.alex.bam input.bam &amp;quot;6&amp;quot;
nextflow run nf-core/hlatyping --bam -profile docker --reads &#39;chr6.alex.bam&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and HLA-typed myself using the &lt;a href=&#34;https://github.com/nf-core/hlatyping&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nf-core/hlatyping&lt;/a&gt; pipeline. Might be just the same curiousity but this worked as well using the data provided and provided me with my HLA-A, HLA-B and HLA-C types. Doing this wasn&amp;rsquo;t possible with the 23andme test back then for example.&lt;/p&gt;
&lt;h3 id=&#34;mtdna--y-typing&#34;&gt;mtDNA / Y Typing&lt;/h3&gt;
&lt;p&gt;Using a simple command, I was able to extract and call the consensus sequence of my mtDNA and type myself to confirm my previous 23and me genotyping results. Fortunately, the &lt;a href=&#34;https://haplogrep.uibk.ac.at/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Haplogrep 2&lt;/a&gt; service and the &lt;a href=&#34;https://github.com/23andMe/yhaplo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Y-Haplo&lt;/a&gt; teams provide their services for everyone and uploading my data there to determine my mtDNA haplogroup and my Y-haplogroup was quit easy, too.&lt;/p&gt;
&lt;h2 id=&#34;future-updates&#34;&gt;Future updates&lt;/h2&gt;
&lt;p&gt;There will be follow up posts once I got more time to look at my data. I will probably integrate my data with population genetics datasets such as Human Origins and also have a more detailed look at some variant analysis methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>nf-core: Community curated bioinformatics pipelines</title>
      <link>https://apeltzer.github.io/publication/09-nfcore/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/09-nfcore/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Complex Genomics Analysis Pipelines made Simple with NextFlow &amp; AWS Batch</title>
      <link>https://apeltzer.github.io/talk/complex-genomics-analysis-pipelines-made-simple-with-nextflow-aws-batch/</link>
      <pubDate>Wed, 27 Feb 2019 15:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/talk/complex-genomics-analysis-pipelines-made-simple-with-nextflow-aws-batch/</guid>
      <description></description>
    </item>
    
    <item>
      <title>nf-core: Community-based best practice pipeline development in Nextflow</title>
      <link>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</link>
      <pubDate>Mon, 25 Feb 2019 11:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://apeltzer.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://apeltzer.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>bioinfo-core teleconference on Nextflow and nf-core</title>
      <link>https://apeltzer.github.io/talk/bioinfo-core-teleconference-on-nextflow-and-nf-core/</link>
      <pubDate>Tue, 06 Nov 2018 15:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/talk/bioinfo-core-teleconference-on-nextflow-and-nf-core/</guid>
      <description></description>
    </item>
    
    <item>
      <title>nf-core: Community-based best practice pipeline development in Nextflow</title>
      <link>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</link>
      <pubDate>Mon, 29 Oct 2018 11:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EAGER2: A modern framework for aDNA analysis</title>
      <link>https://apeltzer.github.io/talk/eager2-a-modern-framework-for-adna-analysis/</link>
      <pubDate>Mon, 15 Oct 2018 10:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/eager2-a-modern-framework-for-adna-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>nf-core: Community-based best practice pipeline development in Nextflow</title>
      <link>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</link>
      <pubDate>Mon, 24 Sep 2018 14:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</guid>
      <description>&lt;p&gt;Slides can be found &lt;a href=&#34;http://bit.ly/hpcbw18&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>nf-core</title>
      <link>https://apeltzer.github.io/project/nfcore/</link>
      <pubDate>Thu, 23 Aug 2018 14:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/project/nfcore/</guid>
      <description>&lt;p&gt;Over at &lt;a href=&#34;https://nf-co.re&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nf-co.re&lt;/a&gt; we are working on solving one of the biggest issues in modern computational biology: How do we make the efforts to analyze various kinds of OMICs data reproducible and thus also accessible to everyone? In the age of &amp;ldquo;fake news&amp;rdquo;, science has to not only answer questions, but also provide means that their findings can be reproduced and not mistakenly used for other malicious or harmful activities. While doing malicious things with OMICs data is certainly hard to pursue, the good practice of making entire analysis procedures reproducible - even years later - remains the biggest motivators for the nf-core project. Our intention is to form a collaborative research platform to enable various bioinformatics researchers to benefit from know-how as generated in this project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Running nf-co.re pipelines with AWSBatch</title>
      <link>https://apeltzer.github.io/post/01-aws-nfcore/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/post/01-aws-nfcore/</guid>
      <description>&lt;p&gt;This document is based on experiences provided by &lt;a href=&#34;https://maxulysse.github.io/2017/11/16/Running-CAW-with-AWS-Batch/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Maxime Garcia&lt;/a&gt; at his blogpost on running CAW with AWSBatch and our own experiences. We just wanted to acknowledge the effort that Maxime also put into making this work!&lt;/p&gt;
&lt;h2 id=&#34;basic-requirements&#34;&gt;Basic Requirements&lt;/h2&gt;
&lt;p&gt;In order to run this, you need to have a &lt;a href=&#34;https://www.google.com/url?q=http://aws.amazon.com&amp;amp;sa=D&amp;amp;ust=1534850604063000&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS
account&lt;/a&gt; set up and create an IAM user for it. More detailed information on how to do this can be found under the above link. The IAM set up is described in the &lt;a href=&#34;#h.iamsetup&#34;&gt;next section&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;iam-user-setuphiamsetup&#34;&gt;&lt;a href=&#34;#h.iamsetup&#34;&gt;IAM User setup&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Please follow the instructions on AWS to set up an IAM user for running
Batch jobs on AWSBatch. This user has to be provided with the required
permissions to run Batch jobs. Permissions on AWS are set up using &lt;a href=&#34;https://www.google.com/url?q=https://console.aws.amazon.com/iam&amp;amp;sa=D&amp;amp;ust=1534850604070000&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the IAM service&lt;/a&gt; and you have to start by creating a new user using the &amp;ldquo;Add user&amp;rdquo; interface. Please attach the following permissions to your newly created user afterwards:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;AmazonEC2FullAccess&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AmazonS3FullAccess&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AWSBatchFullAccess&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This should already suffice in terms of user permissions to run jobs on
AWS Batch.&lt;/p&gt;
&lt;h3 id=&#34;service-role-setuphservicerolesetup&#34;&gt;&lt;a href=&#34;#h.servicerolesetup&#34;&gt;Service role setup&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Next, we need to set up permissions for AWS Batch to e.g. run/stop EC2
instances for us by generating the required roles on IAM. These are
managed as separate roles in IAM under &amp;ldquo;Roles&amp;rdquo;. Some of these are
created automatically for you when you set up a Batch job at the first
time, but we can make sure that these are already present and configured
properly beforehand.&lt;/p&gt;
&lt;p&gt;You need the service roles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;AWSBatchServiceRole&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ecsInstanceRole&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AWSServiceRoleForEC2SpotFleet&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AmazonEC2SpotFleetRole&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The latter two are not required if you are not intending to use spot
instances (you should use them to save money!).&lt;/p&gt;
&lt;h4 id=&#34;awsbatchservicerole&#34;&gt;AWSBatchServiceRole&lt;/h4&gt;
&lt;p&gt;This role should have the policy &lt;code&gt;AWSBatchServiceRole&lt;/code&gt; attached.
&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2018-08-21_awsnfcore/image7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;ecsinstancerole&#34;&gt;ecsInstanceRole&lt;/h4&gt;
&lt;p&gt;This role should have the policies &lt;code&gt;AmazonS3FullAccess&lt;/code&gt; and
&lt;code&gt;AmazonEC2ContainerServiceforEC2Role&lt;/code&gt; set.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2018-08-21_awsnfcore/image1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;awsserviceroleforec2spotfleet&#34;&gt;AWSServiceRoleForEC2SpotFleet&lt;/h4&gt;
&lt;p&gt;This role should have the policy &lt;code&gt;AWSEC2SpotFleetServiceRolePolicy&lt;/code&gt;
set.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2018-08-21_awsnfcore/image6.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;amazonec2spotfleetrole&#34;&gt;AmazonEC2SpotFleetRole&lt;/h4&gt;
&lt;p&gt;This role should have the policies &lt;code&gt;AmazonEC2SpotFleetRole&lt;/code&gt; and
&lt;code&gt;AmazonEC2SpotFleetTaggingRole&lt;/code&gt; set accordingly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2018-08-21_awsnfcore/image8.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once you have set these roles, the permissions for running a job with
the selected IAM user can be used to configure a compute environment
(CE) and a job queue to run your jobs.&lt;/p&gt;
&lt;p&gt;You need to get the accesskey/token combination for using AWS and need
to have these present on the machine starting the jobs in a file
&lt;code&gt;~/.aws/credentials&lt;/code&gt; such as:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[default]
aws_access_key_id = KEY
aws_secret_access_key = secretKEY
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ami&#34;&gt;AMI&lt;/h2&gt;
&lt;p&gt;Now that you have all the permissions set up you need to create a
custom amazon machine image (AMI). This will be used later by the EC2
instances started by AWS batch.&lt;/p&gt;
&lt;h3 id=&#34;ami-preparation&#34;&gt;AMI preparation&lt;/h3&gt;
&lt;p&gt;First you have to set up an EC2 instance which will later be converted
into an AMI. Please use the ECS-Optimized Amazon Linux AMI since it
provides docker installation and configuration.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2018-08-21_awsnfcore/image3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Choose a t2.micro instance for the instance type since the instance
type does not impact the AMI.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2018-08-21_awsnfcore/image4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Configuration of the Instance Details is not needed as the default
configuration should suffice.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2018-08-21_awsnfcore/image9.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Depending on the docker image sizes you expect your Batch instances to
handle, choose a larger EBS storage in the storage configuration.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2018-08-21_awsnfcore/image5.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Optional Tags can be added in Step 5.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apeltzer/starter-academic/master/static/img/2018-08-21_awsnfcore/image2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the last step configure your Security Group. Make sure you can
connect to the EC2 instance when doing so. You can also let AWS create a
security group for you.Now launch the instance.&lt;/p&gt;
&lt;p&gt;Connect to your t2.micro instance and perform the following
steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update the yum repository&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo yum update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Check the docker configuration and make sure the docker storage size matches your configured one.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker info&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Check whether awscli is installed&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aws --version&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install awscli using miniconda&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86\_64.sh
bash Miniconda3-latest-Linux-x86\_64.sh -p /home/ec2-user/miniconda
/home/ec2-user/miniconda/bin/conda install -c conda-forge awscli
/home/ec2-user/miniconda/bin/aws --version
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ami-creation&#34;&gt;AMI creation&lt;/h3&gt;
&lt;p&gt;Now that you have configured your EC2 instance you can logout and stop
the instance.&lt;/p&gt;
&lt;p&gt;In the EC2 Management Console select the stopped instance and choose
the Action Image-&amp;gt;Create Image&lt;/p&gt;
&lt;p&gt;Choose a name and a description and create the AMI.&lt;/p&gt;
&lt;h2 id=&#34;set-up-queue--compute-environment&#34;&gt;Set up QUEUE / Compute Environment&lt;/h2&gt;
&lt;p&gt;In order to submit jobs to AWS Batch, you need to have a working
compute environment (CE) and a JobQueue set up. Start with the CE and
then create a compute environment.&lt;/p&gt;
&lt;h3 id=&#34;compute-environment&#34;&gt;Compute Environment&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Log in to AWS Batch&lt;/li&gt;
&lt;li&gt;Navigation menu: &amp;ldquo;Compute environments&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Create a new compute environment&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Select &amp;ldquo;Managed&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Provide a name for the Compute Environment&lt;/li&gt;
&lt;li&gt;Service role &lt;code&gt;AWSBatchServiceRole&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Instance role &lt;code&gt;ecsInstanceRole&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;EC2 key pair: The key pair of the IAM user you intend to use for
running AWS Batch jobs&lt;/li&gt;
&lt;li&gt;Select &amp;ldquo;on-demand&amp;rdquo; or &amp;ldquo;spot&amp;rdquo; (spot is cheaper)&lt;/li&gt;
&lt;li&gt;Select Maximum Price you&amp;rsquo;re willing to pay for spot instances&lt;/li&gt;
&lt;li&gt;Spot fleet role &lt;code&gt;AmazonEC2SpotFleetRole&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enable user-specified AMI id and provide the
AMI id you created&lt;/li&gt;
&lt;li&gt;If desired, attach a Key/Value pair to make it possible to later
generate e.g. billing information on a per compute environment
basis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Select create and you&amp;rsquo;re all set!&lt;/p&gt;
&lt;h3 id=&#34;jobqueue-set-up&#34;&gt;JobQueue set up&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Log in to AWS Batch&lt;/li&gt;
&lt;li&gt;Select &amp;ldquo;Job queues&amp;rdquo; in Navigation menu&lt;/li&gt;
&lt;li&gt;Provide a name you remember (!) for your job queue&lt;/li&gt;
&lt;li&gt;Set a priority&lt;/li&gt;
&lt;li&gt;Select the previously created compute environment for running jobs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Select create and you&amp;rsquo;re all set!&lt;/p&gt;
&lt;h2 id=&#34;aws-configuration-nextflow&#34;&gt;AWS Configuration Nextflow&lt;/h2&gt;
&lt;p&gt;AWS Batch configuration in Nextflow requires a couple of things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Publicly accessible Docker containers per process or per pipeline&lt;/li&gt;
&lt;li&gt;Executor set to &lt;code&gt;awsbatch&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;JobQueue set to an enabled AWS Batch JobQueue&lt;/li&gt;
&lt;li&gt;An AWS region, e.g. &lt;code&gt;&#39;us-east-1&#39;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;AWSCli present in the AMI which runs the jobs&lt;/li&gt;
&lt;li&gt;S3 Buckets for temporary/work files and results&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example on how to deal with things is to ask your users to specify
the missing parts on pipeline execution. A working example is set in
&lt;a href=&#34;https://github.com/qbicsoftware/ICGC-featureCounts/blob/master/conf/awsbatch.config&amp;amp;sa=D&amp;amp;ust=1534850604086000&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICGC-featureCounts&lt;/a&gt;
where the &lt;code&gt;awsbatch.config&lt;/code&gt; specifies the required parameters for
execution on AWSBatch.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;workDir&lt;/li&gt;
&lt;li&gt;Executor&lt;/li&gt;
&lt;li&gt;Queue&lt;/li&gt;
&lt;li&gt;Region&lt;/li&gt;
&lt;li&gt;And a custom path to AWScli inside the customized AMI to schedule jobs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is then set to default values in the
&lt;a href=&#34;https://github.com/qbicsoftware/ICGC-featureCounts/blob/master/nextflow.config&amp;amp;sa=D&amp;amp;ust=1534850604088000&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nextflow.config&lt;/a&gt; of the pipeline and set according to user specified parameters when executing the pipeline. This way, users don&amp;rsquo;t need to change the &lt;code&gt;awsbatch.config&lt;/code&gt; file but can instead rely on using a set of parameters &lt;code&gt;--workDir, --awsqueue, --awsregion&lt;/code&gt; and should be fine.&lt;/p&gt;
&lt;h2 id=&#34;running-a-basic-job-with-aws-batch&#34;&gt;Running a basic job with AWS Batch&lt;/h2&gt;
&lt;p&gt;You can execute an AWSBatch job on your local workstation or on a
running EC2 instance. For longer running jobs, it might make sense to
use a small EC2 instance (t2.micro) to run your job, as you&amp;rsquo;re not
relying on network connections between your local workstation and the
AWS Batch CE/JobQueue then.&lt;/p&gt;
&lt;p&gt;You can use &lt;code&gt;nextflow cloud create &amp;lt;your-cloud-name&amp;gt;&lt;/code&gt; to launch
a simple instance that has nextflow installed to create a simple
instance for running AWS Batch jobs.&lt;/p&gt;
&lt;p&gt;For this instance additional configuration can be provided in your
&lt;code&gt;nextflow.config&lt;/code&gt;or &lt;code&gt;~/.nextflow/config&lt;/code&gt;file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cloud {
 imageId = &#39;ami-xxxx&#39;
 instanceType = &#39;t2.micro&#39;
 keyName = &amp;lt;AWS keyname&amp;gt;
 userName = &#39;ec2-user&#39;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;h3 id=&#34;i-dont-want-to-risk-requesting-instances-when-nothing-runs-anymore---what-should-i-do&#34;&gt;I don&amp;rsquo;t want to risk requesting instances when nothing runs anymore - what should I do?&lt;/h3&gt;
&lt;p&gt;Simply disable the JobQueue and the Compute Environment and nothing
will be requested when there are no jobs running. In our experience,
failing jobs will also result in instance termination.&lt;/p&gt;
&lt;h3 id=&#34;i-have-configured-nextflow-according-to-your-suggestion-but-every-job-fails-with-essential-container-in-task-exited---how-can-i-fix-that&#34;&gt;I have configured nextflow according to your suggestion but every job fails with Essential container in task exited - how can I fix that?&lt;/h3&gt;
&lt;p&gt;Open CloudWatch and look at the log for the failed task. If the error
is &lt;code&gt;aws command not found&lt;/code&gt; or &lt;code&gt;bash: /home/ec2-user/miniconda/bin/aws&lt;/code&gt;:
No such file or directory&#39; then make sure aws is installed and there are
no typos in your &lt;code&gt;nextflow.config&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;i-found-an-ami-option-for-the-nextflowconfig-file-but-it-doesnt-work---is-it-broken&#34;&gt;I found an AMI option for the nextflow.config file but it doesn&amp;rsquo;t work - is it broken?&lt;/h3&gt;
&lt;p&gt;No, the &lt;code&gt;cloud.ami&lt;/code&gt; configuration is only used for cluster creation. AWS
Batch is a different service and the AMI needs to be specified inside
the compute environment.&lt;/p&gt;
&lt;h3 id=&#34;there-is-no---workdir-option-where-can-i-find-it&#34;&gt;There is no &lt;code&gt;--workDir&lt;/code&gt; option. Where can I find it?&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;--workDir, --awsqueue ,--awsregion&lt;/code&gt; options are provided by the
pipeline. If your pipeline is no nf-core pipeline those options won&amp;rsquo;t be
present. You would have to specify queue and region in your
&lt;code&gt;nextflow.config&lt;/code&gt; file. You can also provide the work directory with the
nextflow parameter &lt;code&gt;-work-dir / -w&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>nf-core: Community-based best practice pipeline development in Nextflow</title>
      <link>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</link>
      <pubDate>Tue, 17 Jul 2018 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</guid>
      <description>&lt;p&gt;Slides can be found &lt;a href=&#34;https://slides.com/apeltzer/sc-nfcore&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>nf-core: Community-based best practice pipeline development in Nextflow</title>
      <link>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</link>
      <pubDate>Fri, 06 Jul 2018 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/nf-core-community-based-best-practice-pipeline-development-in-nextflow/</guid>
      <description>&lt;p&gt;Slides can be found &lt;a href=&#34;bit.ly/ismb2018-nfcore&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data analysis with Nextflow &amp; nf-core</title>
      <link>https://apeltzer.github.io/talk/reproducible-data-analysis-with-nextflow-nf-core/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/reproducible-data-analysis-with-nextflow-nf-core/</guid>
      <description>&lt;p&gt;Slides can be found &lt;a href=&#34;http://bit.ly/nfcoreisc2018&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Inferring genetic origins and phenotypic traits of George Bähr, the architect of the Dresden Frauenkirche</title>
      <link>https://apeltzer.github.io/publication/08-baehr/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/publication/08-baehr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reconstructing Prehistoric African Population Structure</title>
      <link>https://apeltzer.github.io/publication/07-african/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/07-african/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Modern computational methods in ancient DNA analysis</title>
      <link>https://apeltzer.github.io/talk/modern-computational-methods-in-ancient-dna-analysis/</link>
      <pubDate>Mon, 18 Sep 2017 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/modern-computational-methods-in-ancient-dna-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MitoBench and MitoDB: Novel interactive methods for population genetics on mitochondrial DNA</title>
      <link>https://apeltzer.github.io/talk/mitobench-and-mitodb-novel-interactive-methods-for-population-genetics-on-mitochondrial-dna/</link>
      <pubDate>Sun, 03 Sep 2017 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/mitobench-and-mitodb-novel-interactive-methods-for-population-genetics-on-mitochondrial-dna/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Genetic origins of the Minoans and Mycenaeans</title>
      <link>https://apeltzer.github.io/publication/06-greeks/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/06-greeks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ancient Egyptian mummy genomes suggest an increase of Sub-Saharan African ancestry in post-Roman periods</title>
      <link>https://apeltzer.github.io/publication/05-mummies/</link>
      <pubDate>Tue, 30 May 2017 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/05-mummies/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ancient Egyptian mummy genomes suggest an increase of Sub-Saharan African ancestry in post-Roman periods.</title>
      <link>https://apeltzer.github.io/talk/ancient-egyptian-mummy-genomes-suggest-an-increase-of-sub-saharan-african-ancestry-in-post-roman-periods./</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/ancient-egyptian-mummy-genomes-suggest-an-increase-of-sub-saharan-african-ancestry-in-post-roman-periods./</guid>
      <description></description>
    </item>
    
    <item>
      <title>mitoBench: Modern methods for visually enhanced handling of human mitochondrial data and reference retrieval.</title>
      <link>https://apeltzer.github.io/talk/mitobench-modern-methods-for-visually-enhanced-handling-of-human-mitochondrial-data-and-reference-retrieval./</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/mitobench-modern-methods-for-visually-enhanced-handling-of-human-mitochondrial-data-and-reference-retrieval./</guid>
      <description></description>
    </item>
    
    <item>
      <title>Lightweight virtualization using Docker</title>
      <link>https://apeltzer.github.io/talk/lightweight-virtualization-using-docker/</link>
      <pubDate>Sat, 10 Dec 2016 00:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/talk/lightweight-virtualization-using-docker/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Origin of modern syphilis and emergence of a pandemic Treponema pallidum cluster</title>
      <link>https://apeltzer.github.io/publication/04-syphilis/</link>
      <pubDate>Mon, 05 Dec 2016 00:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/publication/04-syphilis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EAGER: Efficient ancient genome Reconstruction</title>
      <link>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</link>
      <pubDate>Mon, 18 Jul 2016 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The genetic history of Ice Age Europe</title>
      <link>https://apeltzer.github.io/publication/03-iceage/</link>
      <pubDate>Mon, 02 May 2016 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/03-iceage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EAGER: efficient ancient genome reconstruction</title>
      <link>https://apeltzer.github.io/publication/02-eager/</link>
      <pubDate>Thu, 31 Mar 2016 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/02-eager/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EAGER: Efficient ancient genome Reconstruction</title>
      <link>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</link>
      <pubDate>Mon, 28 Sep 2015 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EAGER: Efficient ancient genome Reconstruction</title>
      <link>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</link>
      <pubDate>Mon, 13 Jul 2015 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Skin and hair colour prediction based on genetic data.</title>
      <link>https://apeltzer.github.io/talk/skin-and-hair-colour-prediction-based-on-genetic-data./</link>
      <pubDate>Sat, 11 Jul 2015 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/skin-and-hair-colour-prediction-based-on-genetic-data./</guid>
      <description></description>
    </item>
    
    <item>
      <title>EAGER: Efficient ancient genome Reconstruction</title>
      <link>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</link>
      <pubDate>Mon, 03 Nov 2014 00:00:00 +0100</pubDate>
      <guid>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EAGER: Efficient ancient genome Reconstruction</title>
      <link>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</link>
      <pubDate>Thu, 28 Aug 2014 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EAGER: Efficient ancient genome Reconstruction</title>
      <link>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</link>
      <pubDate>Thu, 28 Aug 2014 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/talk/eager-efficient-ancient-genome-reconstruction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>inPHAP: Interactive visualization of genotype and phased haplotype data</title>
      <link>https://apeltzer.github.io/publication/01-inphap/</link>
      <pubDate>Mon, 07 Jul 2014 00:00:00 +0200</pubDate>
      <guid>https://apeltzer.github.io/publication/01-inphap/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
